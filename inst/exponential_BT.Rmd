---
title: "exponential_BT"
author: "robin hankin"
date: "2025-04-02"
output: html_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(hyper2)
library(stringr)
set.seed(0)
```

Basic idea is to have $n$ competitors with BT strengths $\beta, \beta
x,\ldots \beta x^{n-1}$ with $x\in[0,1]$.  The unit sum constraint
gives $\beta=\frac{1-x}{1-x^n}$ but this usually cancels out.  One of
the competitors is the _focal_ competitor with BT strength $\beta
x^{r-1}$ for some $r$ with $1\leqslant r < n$.  Thus $r=1$ means that
the focal competitor is the strongest among the $n$, $r=2$ means he is
the second, and so on.


```{r}
BT <- function(n,x){
    out <- x^(0:(n-1))
    if(x != 1){
        out <- out*(1-x)/(1-x^n)
    } else {
        out <- out/n
    }
    names(out) <- paste0("p",str_pad(1:n,ceiling(log10(n))))
    out
}
BT(4,0.5)
sum(BT(4,0.5))
```

We will consider $n=9$, $x=0.5$, $r=4$ and make repeated observations:


```{r}
(jj <- BT(9,0.5))
o <- tabulate(replicate(1e4,which(rrace(jj) == "p4")))
o
plot(o,type='h')
```


    
```{r, cache=TRUE}
getprob <- function(n, r, x, N=1e4){
    jj <- BT(n, x)
    wanted <- paste0("p", str_pad(r ,ceiling(log10(n))))
    c(r=r, x=x, setNames(tabulate(replicate(N, which(rrace(jj) == wanted)),nbins=n), paste0("p", 1:n)))
}
rbind(
getprob(9,1,0.5,N=100),
getprob(9,2,0.5,N=100),
getprob(9,3,0.5,N=100),
getprob(9,4,0.5,N=100),
getprob(9,5,0.5,N=100),
getprob(9,6,0.5,N=100),
getprob(9,7,0.5,N=100),
getprob(9,8,0.5,N=100),
getprob(9,9,0.5,N=100)
)

rbind(
getprob(9,1,0.2,N=100),
getprob(9,2,0.2,N=100),
getprob(9,3,0.2,N=100),
getprob(9,4,0.2,N=100),
getprob(9,5,0.2,N=100),
getprob(9,6,0.2,N=100),
getprob(9,7,0.2,N=100),
getprob(9,8,0.2,N=100),
getprob(9,9,0.2,N=100)
)
rbind(
getprob(9,1,0.9,N=100),
getprob(9,2,0.9,N=100),
getprob(9,3,0.9,N=100),
getprob(9,4,0.9,N=100),
getprob(9,5,0.9,N=100),
getprob(9,6,0.9,N=100),
getprob(9,7,0.9,N=100),
getprob(9,8,0.9,N=100),
getprob(9,9,0.9,N=100)
)
```

```{r makeII,cache=TRUE}
r_try <- 1:9
x_try <- seq(from = 0.1, to = 1, by = 0.1)
jj <- as.matrix(expand.grid(r_try, x_try))
II <- t(apply(jj, 1, function(v){getprob(9, v[1], v[2], N=1e4)}))
head(II)
```


```{r makesupp, cache=TRUE}
r_true <- 3
x_true <- 0.85
o <- getprob(9, r_true, x_true, 17)  # observations
o[1:2]
o[-(1:2)]

support_func <- function(o, v){
    v <- v[-(1:2)]
    v <- v/sum(v)
    dmultinom(o[-(1:2)], prob=v, log=TRUE)
}
support <- rep(0,nrow(II))
for(i in seq_len(nrow(II))){
    support[i] <- support_func(o,II[i,])
}
```
    
```{r}
support <- support-max(support)
support <- pmax(support, -10)
support  <- matrix(support,length(r_try),length(x_try))
contour(r_try, x_try, support, xlab="r", ylab="x", levels = -(1:5)*2)
abline(v = r_true)
abline(h = x_true)
abline(v = 1:9, col = 'gray', lty = 3, lwd = 0.3)
filled.contour(r_try, x_try, support, xlab = "r", ylab = "x")
```

```{R showjj}
jj <- cbind(II[,1:2],c(support))
jj[jj[,2] == 1,]
```

#  Analysis from a single observation


We translate $\alpha\in [0,1]$ to a number from 1 to $n$ inclusive
with $\lceil n\alpha\rceil$

Write a likelihood function for 9,12 [that is, came 9th in a class of
12] There are 8 better and 3 worse than the focal student.


```{r ninetwelve}
a_try <- seq(from=0.01,to=0.99,len=10)
x_try <- seq(from = 0.1, to = 1, by = 0.1)

single_like_fun <- function(n, a, N=1e4){
    p_try <- ceiling(n * a_try)
    jj <- as.matrix(expand.grid(p_try, x_try))
    II <- t(apply(jj,1,function(v){getprob(n, v[1], v[2], N)}))
    matrix(II[, ceiling(a*n) + 2], length(a_try), length(x_try))
}
```


```{r makesupp912, cache=TRUE}
allsupp <- list(
    log(single_like_fun(12, a =  8/12)),  # pure
    log(single_like_fun(17, a = 12/17)),  # pure
    log(single_like_fun(23, a = 18/23)),  # pure
    log(single_like_fun(14, a =  5/14)),  # applied
    log(single_like_fun(13, a =  3/13)),  # applied
    log(single_like_fun(11, a =  2/11)),  # applied
    log(single_like_fun(13, a =  3/13))   # applied
)
```

```{r showallsupp}
S <- Reduce("+",allsupp)
S <- pmax(S-max(S),-10)
contour(a_try, x_try, S, levels = -1*(1:7))
jj <- which(S == max(S), arr.ind = TRUE)
points(a_try[jj[1]], x_try[jj[2]], pch=16, col = 'red')
```


```{r showbothsupp}
S_pure    <- Reduce("+", allsupp[1:3])
S_applied <- Reduce("+", allsupp[4:7])
S_all     <- Reduce("+", allsupp[1:7])
max(S_all)
max(S_pure)
max(S_applied)
max(S_pure) + max(S_applied)
max(S_pure) + max(S_applied) - max(S_all)
pchisq(max(S_pure) + max(S_applied) - max(S_all),df=2,lower.tail=FALSE)
```




# Parkrun


```{r parkrunlikefun1, cache=TRUE}

# In this chunk, each execution of single_like_fun(...,N=100) takes ~1
# minute

 print(system.time(parkrun01 <- single_like_fun(259, 177/259, N=1e3)))
 print(system.time(parkrun02 <- single_like_fun(305, 222/305, N=1e3)))
 print(system.time(parkrun03 <- single_like_fun(297, 206/297, N=1e3)))
#print(system.time(parkrun04 <- single_like_fun(241, 142/241, N=1e1)))
#print(system.time(parkrun05 <- single_like_fun(179, 118/179, N=1e1)))
#print(system.time(parkrun06 <- single_like_fun(338, 224/338, N=1e1)))
#print(system.time(parkrun07 <- single_like_fun(203, 128/203, N=1e1)))
```

```{r}
parkrun01
parkrun02
parkrun03
#parkrun04
#parkrun05
#parkrun06
#parkrun07
sum(parkrun01)
sum(parkrun02)
sum(parkrun03)
parkrun01 * parkrun02 *parkrun03
sum(parkrun01 * parkrun02 *parkrun03)
```    

