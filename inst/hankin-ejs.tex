\documentclass[ejs,noshowframe]{imsart}

%% Packages
\RequirePackage{amsthm,amsmath,amsfonts,amssymb}
\RequirePackage[numbers]{natbib}
%\RequirePackage[authoryear]{natbib}%% uncomment this for author-year citations
\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}
\RequirePackage{graphicx}

\startlocaldefs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Uncomment next line to change            %%
%% the type of equation numbering           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\numberwithin{equation}{section}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Axiom, Claim, Corollary, Hypothesis, %%
%% Lemma, Theorem, Proposition              %%
%% use \theoremstyle{plain}                 %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{axiom}{Axiom}
\newtheorem{claim}[axiom]{Claim}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Assumption, Definition, Example,     %%
%% Notation, Property, Remark, Fact         %%
%% use \theoremstyle{definition}            %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem*{example}{Example}
\newtheorem*{fact}{Fact}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% For Case use \theoremstyle{remark}       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{remark}
\newtheorem{case}{Case}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please put your definitions here:        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\endlocaldefs

\begin{document}
\begin{frontmatter}
\title{A simplified Plackett-Luce likelihood function for rank orders}
\runtitle{Simplified Plackett-Luce likelihood functions}
%\thankstext{T1}{A sample additional note to the title.}

\begin{aug}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Only one address is permitted per author. %%
%% Only division, organization and e-mail is %%
%% included in the address.                  %%
%% Additional information can be included in %%
%% the Acknowledgments section if necessary. %%
%% ORCID can be inserted by command:         %%
%% \orcid{0000-0000-0000-0000}               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author[A]{\fnms{Robin}~\snm{Hankin}\ead[label=e1]{hankin.robin@gmail.com}},
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Addresses                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\address[A]{Computer Science and Mathematics,
University of Stirling\printead[presep={,\ }]{e1}}

\end{aug}

\begin{abstract}
Here a simplification of the Plackett-Luce likelihood functions for
order statistics is proposed.  We consider a field of $n+1$ entities
that are ordered in some way [the preferred example is competitors in
  a running race, ordered by time of crossing the finishing line].
One entity is of particular interest to us: the ``focal entity'', or
focal competitor.  We assign Placket-Luce strength $a$ to the focal
competitor and $b$ to all others; we require $a+b=1$.  The associated
inference problem appears to have a wide range of applications and I
present some analysis of datasets drawn from the fields of Olympic
athletics, education, and Formula~1 motor racing.
\end{abstract}

\begin{keyword}[class=MSC]
\kwd[Primary ]{6202}
\kwd{Statistical inference under constraints}
\kwd[ ; secondary: Plackett-Luce likelihood functions; ]{62F30}
\end{keyword}


\end{frontmatter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Please use \tableofcontents for articles %%
%% with 50 pages and more                   %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\tableofcontents

\section{Introduction}

Ranked data arises whenever multiple entities are sorted by some
criterion; the preferred interpretation is a race in which the
sufficient statistic is the order of competitors crossing the
finishing line.  The Plackett-Luce likelihood
function~\cite{luce1959,plackett1975} is a generalization of the
Bradley-Terry model~\cite{bradley1952} in which non-negative strengths
are assigned to each competitor; without loss of generality, if the
finishing order is $1,2,\ldots,n$ and competitor $i$ has strength
$p_i\geqslant 0$, then the Plackett-Luce likelihood function will be
proportional to

\begin{equation}\label{plackettluce}
\prod_{i=1}^n\frac{p_i}{\sum_{j=i}^np_j}
\end{equation}

\noindent where the strengths are normalised so $\sum p_i=1$.
However, estimation of the strengths is somewhat difficult if $n$ is
even moderately large: even with as few as 20 competitors following
Zipf's law~\cite{zipf1949} [a typical assumption for Bradley-Terry
  strengths], Hankin~\cite{hankin2017_rmd} shows that maximum
likelihood strengths identify the correct ranking with a probability
of essentially zero.  The situation is worse in cases such as formula
1 motor racing considered below, which requires us to consider
${\mathcal O}(100)$ competitors.

Consider a race between a competitor of Bradley-Terry strength $a$ and
$n$ cloned competitors, each of strength $b=1-a$.  An observation is
indexed by~$r$, the number of strength $b$ clones finishing ahead
of~$a$, and because we have $n+1$ competitors %%%%%%%%%%%%%%%%%%%%%%
$0\leqslant r\leqslant n$.  The initial field strength is
$a+nb=n+(n-1)a$.  The Plackett-Luce likelihood
function~\cite{luce1959,plackett1975} for this situation would be

\begin{eqnarray}\label{likeforrn1}
  \mathcal{L}_{r,n}(a) &=&
\frac{b}{a+ n   b}\cdot
\frac{b}{a+(n-1)b}\cdot
\frac{b}{a+(n-2)b}\cdots
\frac{a}{a+(n-r)b}\\ \label{likeforrn2}
&=& \frac{B-1}{(B+n-1)(B+n-2)\cdots(B+n-r-1)}\\ \label{likeforrn3}
&=& \frac{(B-1)(B+n-r-2)!}{(B+n-1)!}
\end{eqnarray}

\noindent where $B=1/b$.  Note carefully that these expressions are
likelihoods, not probabilities, and do not sum to 1.  Asymptotic
analysis of expression~\ref{likeforrn3} shows that

\begin{equation}\label{asymptotic}
\log\mathcal{L}_{r,n}(a)=\log(B-1)-B\frac{r+1}{n}
+ K + \mathcal{O}\left(n^{-2}\right).
\end{equation}

Using $\mathcal{S}'=\log(B-1)-B\frac{r+1}{n}$ as an approximate support
thus incurs an error of only $\mathcal{O}(n^{-2})$.  Observing that
$\partial^2\mathcal{S'}/\partial B^2=-(B-1)^{-2}<0$, the evaluate
would be unique; we have
$\hat{B}=\frac{n+r+1}{r+1}+\mathcal{O}\left(n^{-1}\right)$, or
alternatively $\hat{a}=\frac{n}{n+r+1}$.  Compare this with the result
of asking ``what is the probability $p$ that the focal competitor
beats a randomly chosen opponent?'' to which the binomial maximum
likelihood estimate is simply $\frac{n-r}{n}$, agreeing to within
$\mathcal{O}(n^{-2})$.  For repeated observations $r_i,n_i$,
$1\leqslant i\leqslant m$ we would have
\begin{equation}
  \hat{a} = 1-
  \frac{\frac{r_1+1}{n_1}+\cdots+\frac{r_m+1}{n_m}}{m}
  = 1-\overline{\left(\frac{r+1}{n}\right)}.
\end{equation}

(that is, one minus the mean ratio of rank to number of [cloned]
competitors); compare the binomial result of $1-\left.\sum
r_i\right/\sum n_i$.

Previous related work presented the case $n=2$ [in current notation].
Considering the case $n=7$ gives us $7+1=8$ distinct likelihood
functions, Figure~\ref{ninelikes}.  We see an unanticipated asymmetry
between $r$ and $n-r$.  For $r=4$ one might expect that
$\hat{a}=\frac{1}{2}$ on the grounds that the focal competitor's
performance was median.  However, $\hat{a}\simeq 0.5886$.

\begin{figure}[t]
\includegraphics[width=4in]{ninelikes}  % ninelikes.pdf produced by very_simplified_likelihood.Rmd
\caption{Likelihood functions for $r=0(1)8$\label{ninelikes}.  Value of $r$ indicated in colour by its curve; vertical line shows $\hat{a}\simeq 0.5886$ for the case $r=4$}
\end{figure}


\begin{figure}[t]
\includegraphics[width=4in]{dotprobs}  % produced by very_simplified_likelihood.Rmd
\caption{Maximum likelihood estimator $\hat{a}$ for $n=1(1)10$ and $r=0(1)n$
  \label{dotprobs}}
\end{figure}


Below, I present three examples that showcase likelihood
function~\ref{likeforrn3}, drawn from the fields of athletics,
education, and Formula~1 motor racing.

\subsection{Olympic track and field athletics}

One long-standing contention in the athletic world is that of lane
bias~\cite{munro2022}.  Running in the inner lane is frequently held
to be a disadvantage; mechanisms include biomechanical issues arising
from centrifugal acceleration, to competitors' inability to see their
rivals.  Here attention is restricted to heats, for which lane placing
is random.  I consider every heat in Men's 100m Olympic running from
2004-2020 (a total of 41 heats, each of 8 or 9 competitors); only
competitors' ranks are used.  Figure~\ref{plotolymp} shows a
log-likelihood curve for the Bradley-Terry strength of the focal
competitor, here the runner in the innermost lane.  We see that the
evaluate of $0.574$ is very close to the neutral value of $0.5$, for
which the support is only $0.16$, far short of Edwards's two units of
support criterion for rejection~\cite{edwards1972}.  This dataset
contains no evidence to support lane bias.

\begin{figure}[t]
\includegraphics[width=4in]{plotolymp} % produced by very_simplified_likelihood.Rmd
\caption{Log-likelihood curve for the Bradley-Terry strength of the
  lane-1 runner, Olympic qualifying heats 2012-2020 \label{plotolymp}}
\end{figure}

\subsection{Education}

In educational research, confidentiality of examination scores is
often an issue, and individual results are generally regarded as
sensitive and private information.  Nevertheless, it is common for a
student to possess some informative observations: the total enrollment
in a specific class and their individual ranking within that class;
table~\ref{educationtable} shows an apocryphal dataset.  What could a
student infer from such data?

\begin{table*}[t]
  \caption{Educational dataset}
\label{educationtable}
\begin{tabular}{llll}
\hline
                   course&category   &rank&class size\\ \hline
      rings and modules  &  pure     & 9  &      12\\
           group theory  &  pure     & 7  &      17\\
               calculus  & applied   & 2  &      23\\
         linear algebra  & applied   & 3  &       9\\
 differential equations  & applied   & 2  &      13\\
               topology  &   pure    & 8  &      14\\
     special relativity  & applied   & 5  &      13\\
        fluid mechanics  & applied   & 4  &      12\\
            Lie algebra  &   pure    & 9  &      15\\
     \hline
\end{tabular}
\end{table*}

One might wonder whether the student was better at pure or applied
mathematics and, if so, to quantify the difference.
Figure~\ref{plotpureandapplied} shows contours of support [again
  normalised so the support of the evaluate is zero] for the dataset,
as a function of pure strength on the horizontal axis and applied
strength on the vertical axis.  A null of equal strengths appears as
the diagonal line.  We see that the maximum likelihood estimate is
$\hat{p}_\mathrm{pure}=0.567$, $\hat{p}_\mathrm{applied}=0.887$.
However, a constrained optimization shows that the maximum support
along the null diagonal is about $-2.43$.  Edwards's two units of
support criterion~\cite{edwards1972} is met, and we are justified in
concluding that the student is indeed more competent at applied than
pure mathematics.  Alternatively, we may observe that
$2\mathcal{S}=4.86$ is in the tail region of its asymptotic $\chi^2_1$
distribution, corresponding to a $p$-value of about $0.028$.

\begin{figure}
\includegraphics[width=4in]{plotpureandapplied}  % plotpureandapplied.pdf produced by very_simplified_likelihood.Rmd
\caption{Contours of equal support for pure (horizontal) and applied
  (vertical) strength; null of equal strengths shown as a diagonal
  line  \label{plotpureandapplied}}
\end{figure}


\subsection{Formula 1}

Formula 1 motor racing is an important and prestigious motor sport
\citep{codling2017,jenkins2010}.  Season ranking is based on a points
allocation system wherein competitors are awarded points based on race
finishing order; points accumulate additively.  The overall
competition winner is the competitor who accumulates the most points
after the final race.  However, as argued by
Hankin~\cite{hankin2023_formula1points}, the drivers' {\em ranks} are
statistically sufficient for analysis using Plackett-Luce approaches.
The methods presented here may be used to assess competitive strengths
of Formula 1 racing driver Sergio P\'{e}rez (``Checo'') over his
career from 2011 to 2023.  Checo's Formula 1 performance began
somewhat inauspiciously as second driver for Sauber for whom he
finished no higher than P7 in 2011, but his performance rose
subsequently, culminating in his achievement of a startling 20 podium
finishes in 2022-3.  Noting that Checo raced against 73 distinct
competitors (this rendering estimation of the other players'
Plackett-Luce strengths effectively impossible~\cite{hankin2020}), we
are nevertheless in a position to consider competitive strength using
the modified likelihood approach presented here.  We consider the
following inference problem:

\begin{equation}
  a = a(t) = \frac{e^{\alpha + \beta t}}{1+e^{\alpha + \beta t}},\qquad\alpha,\beta\in\mathbb{R}
\end{equation}

(that is, a logistic regression of generalized Bradley-Terry strength
$a$ against time $t$, with $\alpha$ and $\beta$ being linear
coefficients).  Contours of equal support are shown in
Figure~\ref{showchecolike}, again normalized so that
$\mathcal{S}(\hat{\alpha},\hat{\beta})=0$.  We see the expected
elliptical contours, and further $H_0\colon\beta=0$ may be rejected in
favour of $\alpha=-0.27$, $\beta=0.081$, on the grounds that
$\mathcal{S}(\alpha,0)\leqslant 9.2$.  Alternatively we may observe
that $2\mathcal{S}=18.4$ would correspond to a $p$-value of about
$1.7\times 10^{-5}$ on its asymptotic $\chi^2_1$ null distribution.

\begin{figure}[t]
\includegraphics[width=4in]{showchecolike}  % showchecolike.pdf produced by very_simplified_likelihood.Rmd
\caption{Log-likelihood contours for $\alpha,\beta$ for Checo's racing
  career 2011-2023\label{showchecolike}}
\end{figure}

\section{Conclusions and further work}

Here a simplification of the Plackett-Luce likelihood functions for
order statistics was proposed, some simple properties obtained, and
inference problems from three disciplines given.  The results seem to
be difficult to obtain any other way.  The assumptions furnish a
reasonable, intuitive, and computationally tractable likelihood
function with wide applicability.  Further work might include the
analysis of more than one focal competitor.

% \begin{acks}[Acknowledgments]
% The authors would like to thank the anonymous referees, an Associate
% Editor and the Editor for their constructive comments that improved the
% quality of this paper.
% \end{acks}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Supplementary Material, including data   %%
%% sets and code, should be provided in     %%
%% {supplement} environment with title      %%
%% and short description. It cannot be      %%
%% available exclusively as external link.  %%
%% All Supplementary Material must be       %%
%% available to the reader on Project       %%
%% Euclid with the published article.       %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{supplement}
\stitle{Very simplified likelihood}
\sdescription{A terse rmarkdown document that  recreates the figures and salient results of the submission}
\end{supplement}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  imsart-???.bst  will be used to                        %%
%%  create a .BBL file for submission.                     %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%  MR numbers will be added by VTeX.                      %%
%%                                                         %%
%%  Use \cite{...} to cite references in text.             %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% if your bibliography is in bibtex format, uncomment commands:
\bibliographystyle{imsart-number} % Style BST file (imsart-number.bst or imsart-nameyear.bst)
\bibliography{hyper2}       % Bibliography file (usually '*.bib')

\end{document}
